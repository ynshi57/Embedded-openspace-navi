# train.pyï¼ˆè¿ç»­è®­ç»ƒç‰ˆæœ¬ï¼‰
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from model_mobilenet_unet import MobileNetV2_UNet
from utils import KittiRoadDataset
import os
import numpy as np
import argparse
from torch.utils.data import ConcatDataset
from torch.utils.data.sampler import WeightedRandomSampler

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("ğŸš€ ä½¿ç”¨è®¾å¤‡:", device)

# åˆå§‹åŒ–æ¨¡å‹
model = MobileNetV2_UNet().to(device)

def create_optimizer_with_different_lr(model, encoder_lr=1e-5, decoder_lr=1e-4, weight_decay=0):
    """åˆ›å»ºåˆ†å±‚å­¦ä¹ ç‡çš„ä¼˜åŒ–å™¨
    
    Args:
        model: MobileNetV2_UNetæ¨¡å‹
        encoder_lr: ç¼–ç å™¨å­¦ä¹ ç‡ï¼ˆé¢„è®­ç»ƒéƒ¨åˆ†ï¼Œè¾ƒå°ï¼‰
        decoder_lr: è§£ç å™¨å­¦ä¹ ç‡ï¼ˆæ–°è®­ç»ƒéƒ¨åˆ†ï¼Œè¾ƒå¤§ï¼‰
        weight_decay: æƒé‡è¡°å‡
    
    Returns:
        optimizer: é…ç½®å¥½çš„ä¼˜åŒ–å™¨
    """
    encoder_params = []
    decoder_params = []
    
    for name, param in model.named_parameters():
        if param.requires_grad:  # åªå¤„ç†éœ€è¦æ¢¯åº¦çš„å‚æ•°
            if 'enc' in name:  # ç¼–ç å™¨å‚æ•°
                encoder_params.append(param)
            else:  # è§£ç å™¨å‚æ•°ï¼ˆup1, up2, up3, up4, final_up, out_convï¼‰
                decoder_params.append(param)
    
    param_groups = []
    
    if encoder_params:
        param_groups.append({
            'params': encoder_params,
            'lr': encoder_lr,
            'weight_decay': weight_decay
        })
        print(f"ç¼–ç å™¨å‚æ•°ç»„: {len(encoder_params)} ä¸ªå‚æ•°, LR={encoder_lr}")
    
    if decoder_params:
        param_groups.append({
            'params': decoder_params,
            'lr': decoder_lr,
            'weight_decay': weight_decay
        })
        print(f"è§£ç å™¨å‚æ•°ç»„: {len(decoder_params)} ä¸ªå‚æ•°, LR={decoder_lr}")
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = torch.optim.Adam(param_groups)
    return optimizer

# åˆ›å»ºä¼˜åŒ–å™¨ï¼ˆé»˜è®¤é…ç½®ï¼‰
optimizer = create_optimizer_with_different_lr(model)

# criterion = nn.BCELoss()
criterion = nn.CrossEntropyLoss(ignore_index=255)

# è®¡ç®—IoUæŒ‡æ ‡
# æ³¨æ„ï¼špredä¸ºlogits (B,C,H,W)ï¼Œtargetä¸ºLongTensor (B,H,W)ï¼Œå¿½ç•¥255
# äºŒç±»æ—¶æŒ‰å‰æ™¯(ç±»1)è®¡ç®—IoU

def calculate_iou_logits(pred_logits, target, num_classes=2, ignore_index=255, foreground_class=1):
    with torch.no_grad():
        pred = torch.argmax(pred_logits, dim=1)  # (B,H,W)
        valid = target != ignore_index
        if valid.sum() == 0:
            return 0.0
        pred_fg = (pred == foreground_class) & valid
        target_fg = (target == foreground_class) & valid
        intersection = (pred_fg & target_fg).sum().float()
        union = (pred_fg | target_fg).sum().float()
        iou = intersection / (union + 1e-6)
        return iou.item()

# Diceç³»æ•°ï¼ˆé’ˆå¯¹å‰æ™¯ç±»ï¼‰
def calculate_dice_logits(pred_logits, target, ignore_index=255, foreground_class=1):
    with torch.no_grad():
        pred = torch.argmax(pred_logits, dim=1)
        valid = target != ignore_index
        if valid.sum() == 0:
            return 0.0
        pred_fg = (pred == foreground_class) & valid
        target_fg = (target == foreground_class) & valid
        intersection = (pred_fg & target_fg).sum().float()
        dice = (2 * intersection) / (pred_fg.sum().float() + target_fg.sum().float() + 1e-6)
        return dice.item()

# åƒç´ å‡†ç¡®ç‡ï¼ˆå¿½ç•¥255ï¼‰
def calculate_pixel_accuracy_logits(pred_logits, target, ignore_index=255):
    with torch.no_grad():
        pred = torch.argmax(pred_logits, dim=1)
        valid = target != ignore_index
        if valid.sum() == 0:
            return 0.0
        correct = (pred[valid] == target[valid]).sum().float()
        total = valid.sum().float()
        return (correct / (total + 1e-6)).item()


def freeze_encoder(model: MobileNetV2_UNet, freeze: bool):
    for m in [model.enc0, model.enc1, model.enc2, model.enc3, model.enc4, model.enc5]:
        for p in m.parameters():
            p.requires_grad = not (not not False) if False else (not False)
    # ä¸Šé¢åªæ˜¯å ä½ï¼ŒçœŸæ­£é€»è¾‘å¦‚ä¸‹ï¼š
    for m in [model.enc0, model.enc1, model.enc2, model.enc3, model.enc4, model.enc5]:
        for p in m.parameters():
            p.requires_grad = not freeze

def build_concat_dataset(image_dirs, mask_dirs, augment: bool):
    assert len(image_dirs) == len(mask_dirs), "image_dirs ä¸ mask_dirs æ•°é‡éœ€ä¸€è‡´"
    datasets = []
    for img_dir, msk_dir in zip(image_dirs, mask_dirs):
        if not os.path.isdir(img_dir) or not os.path.isdir(msk_dir):
            print(f"è·³è¿‡æ— æ•ˆæ•°æ®ç›®å½•: {img_dir} | {msk_dir}")
            continue
        ds = KittiRoadDataset(img_dir, msk_dir, augment=augment)
        if len(ds) == 0:
            print(f"ç©ºæ•°æ®é›†: {img_dir} | {msk_dir}")
            continue
        print(f"åŠ è½½æ•°æ®é›†: {img_dir} ({len(ds)} å¼ )")
        datasets.append(ds)
    if len(datasets) == 0:
        raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®é›†ç›®å½•")
    return ConcatDataset(datasets)

def build_group_datasets(old_imgs, old_msks, new_imgs, new_msks):
    """è¿”å›: (train_old, val_old, train_new, val_new) æŒ‰å„è‡ª80/20åˆ’åˆ†"""
    train_old = val_old = train_new = val_new = None
    if old_imgs and old_msks:
        full_old_aug = build_concat_dataset(old_imgs, old_msks, augment=True)
        n_old = len(full_old_aug)
        idx_old = list(range(n_old))
        split_old = int(0.8 * n_old)
        train_old = torch.utils.data.Subset(full_old_aug, idx_old[:split_old])
        full_old_noaug = build_concat_dataset(old_imgs, old_msks, augment=False)
        val_old = torch.utils.data.Subset(full_old_noaug, idx_old[split_old:])
    if new_imgs and new_msks:
        full_new_aug = build_concat_dataset(new_imgs, new_msks, augment=True)
        n_new = len(full_new_aug)
        idx_new = list(range(n_new))
        split_new = int(0.8 * n_new)
        train_new = torch.utils.data.Subset(full_new_aug, idx_new[:split_new])
        full_new_noaug = build_concat_dataset(new_imgs, new_msks, augment=False)
        val_new = torch.utils.data.Subset(full_new_noaug, idx_new[split_new:])
    return train_old, val_old, train_new, val_new

def train_all_data(total_epochs=50, save_interval=10, resume_from: str = None, resume_optimizer: bool = True,
                   finetune: bool = False, finetune_lr: float = 1e-5, freeze_encoder_epochs: int = 0,
                   image_dirs=None, mask_dirs=None,
                   old_image_dirs=None, old_mask_dirs=None, new_image_dirs=None, new_mask_dirs=None,
                   new_ratio: float = 0.8, encoder_lr: float = 1e-5, decoder_lr: float = 1e-4, weight_decay: float = 0):
    """è¿ç»­è®­ç»ƒæ‰€æœ‰æ•°æ®, æ¯save_intervalè½®ä¿å­˜ä¸€æ¬¡, æœ€ç»ˆåªä¿ç•™ä¸€ä¸ªæ¨¡å‹ã€‚åŠ å…¥éªŒè¯åˆ’åˆ†å¹¶ä¿å­˜æœ€ä½³æ¨¡å‹ã€‚
    æ”¯æŒå¢é‡è®­ç»ƒï¼š
      - resume_from: è·¯å¾„ï¼ŒåŠ è½½æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ
      - finetune: ä»…åŠ è½½æƒé‡,é‡å»ºä¼˜åŒ–å™¨å¹¶ç”¨è¾ƒå°lr, å¯åœ¨å‰è‹¥å¹²epochå†»ç»“encoder
      - image_dirs/mask_dirs: ä¼ å…¥å¤šä¸ªæ•°æ®ç›®å½•ä»¥æ··åˆè®­ç»ƒï¼ˆæ—§+æ–°ï¼‰
      - old/new_* + new_ratio: åˆ†åˆ«æŒ‡å®šæ—§åŸŸå’Œæ–°åŸŸæ•°æ®ï¼ŒæŒ‰æ¯”ä¾‹é‡‡æ ·æ··åˆè®­ç»ƒï¼Œåˆ†åˆ«æ±‡æŠ¥éªŒè¯æŒ‡æ ‡
    """
    # å¤„ç†å¢é‡è®­ç»ƒ/å¾®è°ƒ
    start_epoch = 0
    if resume_from:
        if os.path.exists(resume_from):
            ckpt = torch.load(resume_from, map_location=device)
            if 'model_state_dict' in ckpt:
                model.load_state_dict(ckpt['model_state_dict'])
            else:
                model.load_state_dict(ckpt)
            
            # é‡æ–°åˆ›å»ºä¼˜åŒ–å™¨ï¼ˆä½¿ç”¨åˆ†å±‚å­¦ä¹ ç‡ï¼‰
            if finetune:
                # å¾®è°ƒæ¨¡å¼ï¼šä½¿ç”¨æ›´å°çš„å­¦ä¹ ç‡
                optimizer = create_optimizer_with_different_lr(
                    model, 
                    encoder_lr=finetune_lr * 0.1,  # ç¼–ç å™¨æ›´å°å­¦ä¹ ç‡
                    decoder_lr=finetune_lr,        # è§£ç å™¨ä½¿ç”¨æŒ‡å®šå­¦ä¹ ç‡
                    weight_decay=weight_decay
                )
                print(f"å¾®è°ƒæ¨¡å¼: ä»…åŠ è½½æƒé‡, é‡æ–°åˆ›å»ºä¼˜åŒ–å™¨")
                print(f"  ç¼–ç å™¨LR: {finetune_lr * 0.1}, è§£ç å™¨LR: {finetune_lr}")
            else:
                # æ–­ç‚¹ç»­è®­ï¼šä½¿ç”¨æ­£å¸¸å­¦ä¹ ç‡
                optimizer = create_optimizer_with_different_lr(
                    model, 
                    encoder_lr=encoder_lr, 
                    decoder_lr=decoder_lr, 
                    weight_decay=weight_decay
                )
                
                if resume_optimizer and 'optimizer_state_dict' in ckpt:
                    try:
                        optimizer.load_state_dict(ckpt['optimizer_state_dict'])
                        print("æ–­ç‚¹ç»­è®­: å·²æ¢å¤ä¼˜åŒ–å™¨çŠ¶æ€")
                    except Exception as e:
                        print(f"ä¼˜åŒ–å™¨çŠ¶æ€æ¢å¤å¤±è´¥: {e}")
                        print("å°†ä½¿ç”¨æ–°çš„ä¼˜åŒ–å™¨é…ç½®ç»§ç»­è®­ç»ƒ")
                
                if 'epoch' in ckpt:
                    start_epoch = int(ckpt['epoch'])
                elif 'final_epoch' in ckpt:
                    start_epoch = int(ckpt['final_epoch'])
                else:
                    start_epoch = 0
                print(f"ä»ç¬¬ {start_epoch+1} è½®ç»§ç»­è®­ç»ƒ")
        else:
            print(f"resume_from è·¯å¾„ä¸å­˜åœ¨: {resume_from}ï¼Œå°†ä»å¤´è®­ç»ƒ")
            # ä»å¤´è®­ç»ƒï¼šåˆ›å»ºæ–°çš„ä¼˜åŒ–å™¨
            optimizer = create_optimizer_with_different_lr(
                model, 
                encoder_lr=encoder_lr, 
                decoder_lr=decoder_lr, 
                weight_decay=weight_decay
            )
    else:
        # ä»å¤´è®­ç»ƒï¼šåˆ›å»ºæ–°çš„ä¼˜åŒ–å™¨
        optimizer = create_optimizer_with_different_lr(
            model, 
            encoder_lr=encoder_lr, 
            decoder_lr=decoder_lr, 
            weight_decay=weight_decay
        )

    # æ•°æ®é›†æ„å»º
    # ä¼˜å…ˆä½¿ç”¨ old/new åˆ†ç»„ï¼›è‹¥æœªæä¾›ï¼Œåˆ™å›é€€åˆ° image_dirs/mask_dirsï¼›å†å›é€€åˆ°é»˜è®¤ freespace_dataset
    if (old_image_dirs and old_mask_dirs) or (new_image_dirs and new_mask_dirs):
        train_old, val_old, train_new, val_new = build_group_datasets(old_image_dirs, old_mask_dirs, new_image_dirs, new_mask_dirs)
        train_parts = []
        val_parts = []
        n_old = len(train_old) if train_old is not None else 0
        n_new = len(train_new) if train_new is not None else 0
        if train_old is not None:
            train_parts.append(train_old)
        if train_new is not None:
            train_parts.append(train_new)
        if len(train_parts) == 0:
            raise ValueError("æœªæä¾›æœ‰æ•ˆçš„è®­ç»ƒæ•°æ®")
        train_mixed = ConcatDataset(train_parts)
        # éªŒè¯é›†ï¼šåˆ†åˆ«ä¿ç•™
        val_mixed = None
        if val_old is not None and val_new is not None:
            val_mixed = ConcatDataset([val_old, val_new])
        elif val_old is not None:
            val_mixed = val_old
        elif val_new is not None:
            val_mixed = val_new
        # é‡‡æ ·æƒé‡ï¼šæŒ‰ new_ratio å¯¹æ–°åŸŸé‡‡æ ·å€¾æ–œ
        sample_weights = []
        for i in range(len(train_mixed)):
            # ConcatDatasetå°†å­é›†é¡ºåºæ‹¼æ¥ï¼šå…ˆoldånewï¼ˆè‹¥ä¸¤è€…éƒ½å­˜åœ¨ä¸”æŒ‰ä¸Šè¿°appendé¡ºåºï¼‰
            if train_old is not None and i < len(train_old):
                # old
                w = max(1e-6, (1.0 - new_ratio) / max(1, n_old))
            else:
                # new
                w = max(1e-6, new_ratio / max(1, n_new))
            sample_weights.append(w)
        sampler = WeightedRandomSampler(weights=torch.DoubleTensor(sample_weights), num_samples=len(train_mixed), replacement=True)
        train_loader = DataLoader(train_mixed, batch_size=4, sampler=sampler)
        val_loader_mixed = DataLoader(val_mixed, batch_size=4, shuffle=False) if val_mixed is not None else None
        val_loader_old = DataLoader(val_old, batch_size=4, shuffle=False) if val_old is not None else None
        val_loader_new = DataLoader(val_new, batch_size=4, shuffle=False) if val_new is not None else None
        total_train = len(train_mixed)
        total_val = len(val_mixed) if val_mixed is not None else 0
        print(f"ğŸ“Š è®­ç»ƒé›†(æ··åˆ): {total_train} å¼  | éªŒè¯(æ··åˆ): {total_val} å¼  | éªŒè¯(æ—§): {len(val_old) if val_old else 0} | éªŒè¯(æ–°): {len(val_new) if val_new else 0}")
    else:
        # å›é€€ï¼šåŸå…ˆæ··åˆåˆ—è¡¨æˆ–é»˜è®¤æ•°æ®
        if not image_dirs:
            image_dirs = ["freespace_dataset/images"]
        if not mask_dirs:
            mask_dirs = ["freespace_dataset/masks"]
        full_dataset = build_concat_dataset(image_dirs, mask_dirs, augment=True)
        n = len(full_dataset)
        indices = list(range(n))
        split = int(0.8 * n)
        train_indices = indices[:split]
        val_indices = indices[split:]
        train_subset = torch.utils.data.Subset(full_dataset, train_indices)
        val_full = build_concat_dataset(image_dirs, mask_dirs, augment=False)
        val_subset = torch.utils.data.Subset(val_full, val_indices)
        train_loader = DataLoader(train_subset, batch_size=4, shuffle=True)
        val_loader_mixed = DataLoader(val_subset, batch_size=4, shuffle=False)
        val_loader_old = None
        val_loader_new = None
        print(f"ğŸ“Š è®­ç»ƒé›†: {len(train_subset)} å¼  | éªŒè¯é›†: {len(val_subset)} å¼  (æ€»è®¡: {n})")

    best_val_iou_mixed = -1.0

    for epoch in range(start_epoch, total_epochs):
        if freeze_encoder_epochs > 0 and (epoch - start_epoch) < freeze_encoder_epochs:
            freeze_encoder(model, True)
            if (epoch - start_epoch) == 0:
                print(f"ğŸ§Š å†»ç»“Encoderå‚æ•° {freeze_encoder_epochs} ä¸ªepoch ä»¥ç¨³å®šå¾®è°ƒ")
        else:
            freeze_encoder(model, False)

        model.train()
        epoch_loss = 0.0
        epoch_iou = 0.0
        epoch_dice = 0.0
        epoch_acc = 0.0
        
        for batch_idx, (images, masks) in enumerate(train_loader):
            images, masks = images.to(device), masks.to(device)
            preds = model(images)
            loss = criterion(preds, masks)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            with torch.no_grad():
                iou = calculate_iou_logits(preds, masks)
                dice = calculate_dice_logits(preds, masks)
                acc = calculate_pixel_accuracy_logits(preds, masks)
            epoch_loss += loss.item()
            epoch_iou += iou
            epoch_dice += dice
            epoch_acc += acc
        
        avg_loss = epoch_loss / len(train_loader)
        avg_iou = epoch_iou / len(train_loader)
        avg_dice = epoch_dice / len(train_loader)
        avg_acc = epoch_acc / len(train_loader)

        # éªŒè¯
        def eval_loader(dl):
            if dl is None or len(dl) == 0:
                return float('nan'), float('nan'), float('nan'), float('nan')
            viou = vdice = vacc = vloss = 0.0
            with torch.no_grad():
                for images, masks in dl:
                    images, masks = images.to(device), masks.to(device)
                    preds = model(images)
                    loss = criterion(preds, masks)
                    vloss += loss.item()
                    viou += calculate_iou_logits(preds, masks)
                    vdice += calculate_dice_logits(preds, masks)
                    vacc += calculate_pixel_accuracy_logits(preds, masks)
            n = len(dl)
            return vloss / n, viou / n, vdice / n, vacc / n

        val_loss_m, val_iou_m, val_dice_m, val_acc_m = eval_loader(val_loader_mixed)
        val_loss_o, val_iou_o, val_dice_o, val_acc_o = eval_loader(val_loader_old)
        val_loss_n, val_iou_n, val_dice_n, val_acc_n = eval_loader(val_loader_new)
        
        print(f"[{epoch+1}/{total_epochs}] Train Loss: {avg_loss:.4f} | IoU: {avg_iou:.4f} | Dice: {avg_dice:.4f} | Acc: {avg_acc:.4f}")
        print(f"                 Val(mix) Loss: {val_loss_m:.4f} | IoU: {val_iou_m:.4f} | Dice: {val_dice_m:.4f} | Acc: {val_acc_m:.4f}")
        if not np.isnan(val_iou_o):
            print(f"                 Val(old) Loss: {val_loss_o:.4f} | IoU: {val_iou_o:.4f} | Dice: {val_dice_o:.4f} | Acc: {val_acc_o:.4f}")
        if not np.isnan(val_iou_n):
            print(f"                 Val(new) Loss: {val_loss_n:.4f} | IoU: {val_iou_n:.4f} | Dice: {val_dice_n:.4f} | Acc: {val_acc_n:.4f}")

        # ä¿å­˜æœ€ä½³ï¼ˆä»¥æ··åˆéªŒè¯IoUä¸ºå‡†ï¼‰
        if not np.isnan(val_iou_m) and val_iou_m > best_val_iou_mixed:
            best_val_iou_mixed = val_iou_m
            os.makedirs("runs", exist_ok=True)
            best_path = "runs/best_model_val_iou.pth"
            torch.save({
                'epoch': epoch + 1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'train_metrics': {
                    'loss': avg_loss,
                    'iou': avg_iou,
                    'dice': avg_dice,
                    'acc': avg_acc
                },
                'val_mixed': {
                    'loss': val_loss_m,
                    'iou': val_iou_m,
                    'dice': val_dice_m,
                    'acc': val_acc_m
                },
                'val_old': {
                    'loss': val_loss_o,
                    'iou': val_iou_o,
                    'dice': val_dice_o,
                    'acc': val_acc_o
                },
                'val_new': {
                    'loss': val_loss_n,
                    'iou': val_iou_n,
                    'dice': val_dice_n,
                    'acc': val_acc_n
                }
            }, best_path)
            print(f"ğŸ† æ›´æ–°æœ€ä½³æ¨¡å‹(Val-mix IoU={val_iou_m:.4f}) â†’ {best_path}")
        
        if (epoch + 1) % save_interval == 0:
            os.makedirs("runs", exist_ok=True)
            checkpoint_path = f"runs/checkpoint_epoch_{epoch+1}.pth"
            torch.save({
                'epoch': epoch + 1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': avg_loss,
                'iou': avg_iou,
                'dice': avg_dice,
                'acc': avg_acc,
                'val_mixed': {
                    'loss': val_loss_m,
                    'iou': val_iou_m,
                    'dice': val_dice_m,
                    'acc': val_acc_m
                },
                'val_old': {
                    'loss': val_loss_o,
                    'iou': val_iou_o,
                    'dice': val_dice_o,
                    'acc': val_acc_o
                },
                'val_new': {
                    'loss': val_loss_n,
                    'iou': val_iou_n,
                    'dice': val_dice_n,
                    'acc': val_acc_n
                }
            }, checkpoint_path)
            print(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path}")

    # è®­ç»ƒå®Œæˆï¼Œä¿å­˜æœ€ç»ˆæ¨¡å‹
    os.makedirs("runs", exist_ok=True)
    final_model_path = "runs/freespace_model.pth"
    torch.save({
        'final_epoch': total_epochs,
        'model_state_dict': model.state_dict(),
        'best_val_iou_mixed': best_val_iou_mixed,
        'final_metrics': {
            'loss': avg_loss,
            'iou': avg_iou,
            'dice': avg_dice,
            'acc': avg_acc,
            'val_mixed_iou': val_iou_m,
            'val_old_iou': val_iou_o,
            'val_new_iou': val_iou_n
        }
    }, final_model_path)

    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“ æœ€ç»ˆæ¨¡å‹: {final_model_path}")
    print(f"ğŸ† æœ€ä½³æ··åˆéªŒè¯IoU: {best_val_iou_mixed:.4f}")
    print(f"ğŸ“Š æœ€ç»ˆæŒ‡æ ‡:")
    print(f"   Train Loss: {avg_loss:.4f} | IoU: {avg_iou:.4f} | Dice: {avg_dice:.4f} | Acc: {avg_acc:.4f}")
    print(f"   Val(mix)  Loss: {val_loss_m:.4f} | IoU: {val_iou_m:.4f} | Dice: {val_dice_m:.4f} | Acc: {val_acc_m:.4f}")
    if not np.isnan(val_iou_o):
        print(f"   Val(old)  Loss: {val_loss_o:.4f} | IoU: {val_iou_o:.4f} | Dice: {val_dice_o:.4f} | Acc: {val_acc_o:.4f}")
    if not np.isnan(val_iou_n):
        print(f"   Val(new)  Loss: {val_loss_n:.4f} | IoU: {val_iou_n:.4f} | Dice: {val_dice_n:.4f} | Acc: {val_acc_n:.4f}")

    for i in range(save_interval, total_epochs + 1, save_interval):
        checkpoint_path = f"runs/checkpoint_epoch_{i}.pth"
        if os.path.exists(checkpoint_path):
            os.remove(checkpoint_path)
            print(f"ğŸ—‘ï¸ åˆ é™¤æ£€æŸ¥ç‚¹: {checkpoint_path}")

    return final_model_path

# å¼€å§‹è®­ç»ƒ
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    # è®­ç»ƒæ€»è½®æ•°ï¼ˆé»˜è®¤50ï¼‰ã€‚å¢é‡/å¾®è°ƒåœºæ™¯ä¸‹ä¸€æ ·ç”Ÿæ•ˆï¼šä¼šä»èµ·å§‹epochç»§ç»­åˆ°è¯¥è½®æ•°
    parser.add_argument('--epochs', type=int, default=50)

    # å‘¨æœŸæ€§ä¿å­˜é—´éš”ï¼ˆå•ä½ï¼šepochï¼‰ã€‚ä»…ç”¨äºä¸­é€”æ£€æŸ¥ç‚¹ï¼›è®­ç»ƒç»“æŸä¼šæ¸…ç†è¿™äº›æ£€æŸ¥ç‚¹
    parser.add_argument('--save_interval', type=int, default=10)

    # æ¢å¤è®­ç»ƒ/å¾®è°ƒçš„æƒé‡è·¯å¾„ï¼ˆ.pthï¼‰ã€‚å¯ä¸º runs/best_model_val_iou.pth æˆ–è‡ªå®šä¹‰
    parser.add_argument('--resume_from', type=str, default=None, help='checkpoint path to resume/finetune from')

    # æ˜¯å¦åœ¨æ–­ç‚¹ç»­è®­æ—¶ä¸€å¹¶æ¢å¤ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆåŠ¨é‡/å­¦ä¹ ç‡ç­‰ï¼‰ã€‚ä»…æ–­ç‚¹ç»­è®­å»ºè®®å¼€å¯ï¼Œå¾®è°ƒä¸€èˆ¬å…³é—­
    parser.add_argument('--resume_optimizer', action='store_true', help='resume optimizer state when resuming')

    # å¾®è°ƒæ¨¡å¼ï¼šä»…åŠ è½½æ¨¡å‹æƒé‡ï¼Œé‡å»ºä¼˜åŒ–å™¨ï¼Œä»¥è¾ƒå°å­¦ä¹ ç‡åœ¨æ–°æ•°æ®ä¸Šç»§ç»­è®­ç»ƒ
    parser.add_argument('--finetune', action='store_true', help='finetune on new data (load weights only)')

    # å¾®è°ƒå­¦ä¹ ç‡ï¼ˆé»˜è®¤1e-5ï¼‰ã€‚ä¸ --finetune æ­é…ä½¿ç”¨
    parser.add_argument('--finetune_lr', type=float, default=1e-5, help='lr for finetune')

    # å¾®è°ƒæ—¶å¯å…ˆå†»ç»“ç¼–ç å™¨è‹¥å¹²è½®ï¼ˆé»˜è®¤0ï¼‰ï¼Œç¨³å®šç‰¹å¾å†è§£å†»ã€‚å…¸å‹è®¾ç½®ï¼š2~5
    parser.add_argument('--freeze_encoder_epochs', type=int, default=0, help='freeze encoder for first N epochs')

    # ç»Ÿä¸€æ··åˆè®­ç»ƒæ¨¡å¼ï¼šå¯ä¼ å…¥å¤šä¸ªå›¾åƒ/æ©ç ç›®å½•è¿›è¡Œåˆå¹¶è®­ç»ƒï¼ˆæœªæä¾› old/new æ—¶ç”Ÿæ•ˆï¼‰
    parser.add_argument('--image_dirs', nargs='+', type=str, default=None, help='one or more image directories')
    parser.add_argument('--mask_dirs', nargs='+', type=str, default=None, help='one or more mask directories')

    # åˆ†åŸŸæ··åˆè®­ç»ƒï¼šåˆ†åˆ«æŒ‡å®šæ—§åŸŸä¸æ–°åŸŸæ•°æ®ç›®å½•ï¼Œç”¨äºâ€œæ–°æ•°æ®ä¸ºä¸»+æ—§æ•°æ®å›æ”¾â€çš„æŒç»­å­¦ä¹ èŒƒå¼
    parser.add_argument('--old_image_dirs', nargs='+', type=str, default=None, help='old domain image dirs')
    parser.add_argument('--old_mask_dirs', nargs='+', type=str, default=None, help='old domain mask dirs')
    parser.add_argument('--new_image_dirs', nargs='+', type=str, default=None, help='new domain image dirs')
    parser.add_argument('--new_mask_dirs', nargs='+', type=str, default=None, help='new domain mask dirs')
    
    # æ–°åŸŸé‡‡æ ·å æ¯”ï¼ˆ0~1ï¼Œé»˜è®¤0.8ï¼‰ã€‚ä»…åœ¨æä¾› old/new ç›®å½•æ—¶ç”Ÿæ•ˆï¼Œç”¨äºåŠ æƒé‡‡æ ·æ–°åŸŸæ ·æœ¬
    parser.add_argument('--new_ratio', type=float, default=0.8, help='sampling ratio for new domain in training (0~1)')
    
    # åˆ†å±‚å­¦ä¹ ç‡å‚æ•°
    parser.add_argument('--encoder_lr', type=float, default=1e-5, help='learning rate for encoder (pretrained parts)')
    parser.add_argument('--decoder_lr', type=float, default=1e-4, help='learning rate for decoder (new training parts)')
    parser.add_argument('--weight_decay', type=float, default=0, help='weight decay for all parameters')

    # ä½¿ç”¨ç¤ºä¾‹ï¼š
    # 1) æ–­ç‚¹ç»­è®­ï¼ˆåŒä¸€æ•°æ®ç»§ç»­è®­ç»ƒï¼Œæ¢å¤ä¼˜åŒ–å™¨ï¼‰
    #    python3 train.py --epochs 50 \
    #        --resume_from runs/best_model_val_iou.pth --resume_optimizer
    # 2) æ–°æ•°æ®å¾®è°ƒï¼ˆå°å­¦ä¹ ç‡ + å†»ç»“ç¼–ç å™¨å‰2è½®ï¼‰ï¼Œæ–°åŸŸå æ¯”80%ï¼Œæ··å…¥æ—§æ•°æ®å›æ”¾20%
    #    python3 train.py \
    #        --old_image_dirs freespace_dataset/images \
    #        --old_mask_dirs freespace_dataset/masks \
    #        --new_image_dirs NEW/images \
    #        --new_mask_dirs NEW/masks \
    #        --new_ratio 0.8 \
    #        --resume_from runs/best_model_val_iou.pth \
    #        --finetune --finetune_lr 1e-5 --freeze_encoder_epochs 2
    # 3) åˆ†å±‚å­¦ä¹ ç‡è®­ç»ƒï¼ˆç¼–ç å™¨å°å­¦ä¹ ç‡ï¼Œè§£ç å™¨å¤§å­¦ä¹ ç‡ï¼‰
    #    python3 train.py --epochs 50 \
    #        --encoder_lr 1e-5 --decoder_lr 1e-4 --weight_decay 1e-4
    # 4) å¾®è°ƒæ—¶ä½¿ç”¨åˆ†å±‚å­¦ä¹ ç‡
    #    python3 train.py --epochs 30 \
    #        --resume_from runs/best_model_val_iou.pth \
    #        --finetune --finetune_lr 1e-5 \
    #        --encoder_lr 1e-6 --decoder_lr 1e-5 --weight_decay 1e-4

    args = parser.parse_args()

    final_model = train_all_data(
        total_epochs=args.epochs,
        save_interval=args.save_interval,
        resume_from=args.resume_from,
        resume_optimizer=args.resume_optimizer,
        finetune=args.finetune,
        finetune_lr=args.finetune_lr,
        freeze_encoder_epochs=args.freeze_encoder_epochs,
        image_dirs=args.image_dirs,
        mask_dirs=args.mask_dirs,
        old_image_dirs=args.old_image_dirs,
        old_mask_dirs=args.old_mask_dirs,
        new_image_dirs=args.new_image_dirs,
        new_mask_dirs=args.new_mask_dirs,
        new_ratio=args.new_ratio,
        encoder_lr=args.encoder_lr,
        decoder_lr=args.decoder_lr,
        weight_decay=args.weight_decay,
    )
